Dataset ID: c9c3d9c463f94e0a669f092b35273668
tag project=mlincub-project

Reference for Dataset Export:
https://catalog.us-east-1.prod.workshops.aws/workshops/e5548031-3004-49ad-89be-a13e8cd616f6/en-US/subscriber-and-export-data/one-time-export
Task 1 - Simple Option selected
Reference: https://catalog.us-east-1.prod.workshops.aws/workshops/ee59d21b-4cb8-4b3d-a629-24537cf37bb5/en-US/lab1/create-crawler-cli
https://docs.aws.amazon.com/cli/latest/reference/glue/create-crawler.html

# Use command: "aws glue help" to see available help options.

# Create a Glue Database from CLI
aws glue create-database --database-input "{\"Name\":\"covid-test-db\"}"     

Before creating a crawler create a role with policies:
 - AWSGlueServiceRole: Trust policy that enables Glue to assume the role
 - An inline policy that provides access to the specific S3 bucket
   s3:PutObject and s3:GetObject access is needed by the crawler.


{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:GetObject"
            ],
            "Resource": "arn:aws:s3:::covid-dataset-rakesh/*"
        }
    ]
}


# Create a Glue Database from CLI
aws glue create-database --database-input "{\"Name\":\"covid-test-db\"}"

# csv crawler
aws glue create-crawler \
--name covid-s3-crawler-csv \
--role AWSGlueServiceRole-mlincub \
--database-name covid-test-db \
--targets "{\"S3Targets\": [\
        {\
            \"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset\",\
            \"Exclusions\": [\"**.json\"] \
        }\
    ]}" \
--recrawl-policy "{\"RecrawlBehavior\": \"CRAWL_NEW_FOLDERS_ONLY\"}" \
--tags "{\"KeyName\": \"project\", \"Value\": \"mlincub\"}"

# start csv crawler
aws glue start-crawler --name covid-s3-crawler-csv


## Create JSON tables

# Command to create custom classifier (Not Working)
aws glue create-classifier --json-classifier "{ \
    \"Name\": \"MyJsonClassifier1\", \
    \"JsonPath\": \"$[*]\" \
    }"


# TableLevelConfiguration:4 gives one table json_json
# TableLevelConfiguration:5 gives 6 tables but does not recognize the schema
# Crawler able to identify schema with custom classifier
aws glue create-crawler \
--name covid-s3-crawler-json \
--role AWSGlueServiceRole-mlincub \
--database-name covid-test-db \
--targets "{\"S3Targets\": [\
        {\
            \"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset\",\
            \"Exclusions\": [\"**.csv\"] \
        }\
    ]}" \
--table-prefix json_ \
--recrawl-policy "{\"RecrawlBehavior\": \"CRAWL_NEW_FOLDERS_ONLY\"}" \
--tags "{\"KeyName\": \"project\", \"Value\": \"mlincub\"}" \
--configuration "{\"Version\": 1.0, \"Grouping\": {\"TableLevelConfiguration\":5}}" \
--classifiers MyJSONClassifier1


# This option also failed to identify schema
# json crawler
aws glue create-crawler \
--name covid-s3-crawler-json \
--role AWSGlueServiceRole-mlincub \
--database-name covid-test-db \
--targets "{\"S3Targets\": [\
        {\"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset/json/states_current\"}, \
        {\"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset/json/states_daily\"}, \
        {\"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset/json/states_info\"}, \
        {\"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset/json/states_screenshots\"}, \
        {\"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset/json/us_current\"}, \
        {\"Path\": \"s3://covid-dataset-rakesh/ordered-data/dataset/json/us_daily\"} \
    ]}" \
--table-prefix json_ \
--recrawl-policy "{\"RecrawlBehavior\": \"CRAWL_NEW_FOLDERS_ONLY\"}" \
--tags "{\"KeyName\": \"project\", \"Value\": \"mlincub\"}" \
--configuration "{\"Version\": 1.0, \"Grouping\": {\"TableLevelConfiguration\":5}}"



############################## Glue Local ###################################
# For AWS Glue version 4.0
docker pull amazon/aws-glue-libs:glue_libs_4.0.0_image_01

Set AWS_PROFILE and JUPYTER_WORKSPACE_LOCATION environment variable

docker run -it -v ~/.aws:/home/glue_user/.aws \
-v $JUPYTER_WORKSPACE_LOCATION:/home/glue_user/workspace/jupyter_workspace/ \
-e AWS_PROFILE=$AWS_PROFILE -e DISABLE_SSL=true --rm -p 4040:4040 -p 18080:18080 \
-p 8998:8998 -p 8888:8888 \
--name glue_jupyter_lab amazon/aws-glue-libs:glue_libs_4.0.0_image_01 \
/home/glue_user/jupyter/jupyter_start.sh

Open http://127.0.0.1:8888/lab and choose Glue Spark Local (PySpark) under Notebook.

